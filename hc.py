import os
import time
import gc
from concurrent.futures import ProcessPoolExecutor, as_completed
from multiprocessing import Manager

import cv2
import numpy as np
import threading
import torch

from detect_core.castfilm_detector import CastFilmDefectDetector
from detect_core.defect_classifier import DefectClassifier
from detect_core.defect_config import DefectConfig
from utils.light_util import light_judge  # âœ… å…‰ç…§æ£€æµ‹å‡½æ•°


# ------------------------
# 1. å…¨å±€æ£€æµ‹å™¨åˆå§‹åŒ–å‡½æ•°ï¼ˆä¾›è¿›ç¨‹æ± å…±äº«ï¼‰
# ------------------------
_detector = None


def _init_detector():
    """åœ¨æ¯ä¸ªå­è¿›ç¨‹é‡Œåˆå§‹åŒ–ä¸€æ¬¡ CastFilm æ£€æµ‹å™¨"""
    global _detector
    _detector = CastFilmDefectDetector()


def imread_unicode(path, flags=cv2.IMREAD_GRAYSCALE):
    """å®‰å…¨è¯»å–å›¾ç‰‡ï¼Œæ”¯æŒä¸­æ–‡è·¯å¾„"""
    try:
        with open(path, "rb") as f:
            file_bytes = np.frombuffer(f.read(), dtype=np.uint8)
            img = cv2.imdecode(file_bytes, flags)
            return img
    except Exception as e:
        print(f"âš ï¸ æ— æ³•è¯»å–æ–‡ä»¶: {os.path.basename(path)}, é”™è¯¯: {e}")
        return None


def _segment_one_image(image_path):
    """
    å­è¿›ç¨‹åˆ†å‰²ä»»åŠ¡ï¼š
    1) è¯»å–ç°åº¦å›¾
    2) è°ƒç”¨ CastFilmDefectDetector.detect_defects_fast
    è¿™é‡Œåªä¿ç•™ç¼ºé™·æ¡†ï¼Œä¸åšä»»ä½•ä¿å­˜/å‰ç«¯äº¤äº’
    """
    try:
        global _detector
        image_np_gray = imread_unicode(image_path, cv2.IMREAD_GRAYSCALE)
        if image_np_gray is None:
            return False, image_path, []

        defects, left_edge_x, right_edge_x = _detector.detect_defects_fast(image_np_gray)
        # è¿™é‡Œåªè¿”å› defects å³å¯ï¼Œè¾¹ç•Œå¦‚ä¸éœ€è¦å¯ä»¥ä¸ç”¨
        return True, image_path, defects
    except Exception as e:
        print(f"âš ï¸ åˆ†å‰²é˜¶æ®µå‡ºé”™: {os.path.basename(image_path)}, é”™è¯¯: {e}")
        return False, image_path, []


# ------------------------
# 2. åˆ†ç±» + ç»Ÿè®¡
# ------------------------
def process_dataset(classify_result, count):
    """
    ä»…æ›´æ–°ç»Ÿè®¡è®¡æ•°å™¨ï¼š
    å¯¹äºæ¯ä¸ªç¼ºé™·ï¼š
        - å– defect_classï¼ˆé»‘ç‚¹/æ™¶ç‚¹/çº¤ç»´/å…¶å®ƒï¼‰
        - å– size_index â†’ SIZE_LIST åç§°
        - åœ¨ count[defect_class][size_name] é‡Œ +1
    """
    cut_images = classify_result.get('cut_images', [])
    defect_infos = classify_result.get('defect_infos', [])
    for _, defect_info in zip(cut_images, defect_infos):
        defect_class = defect_info.get('defect_class', 'å…¶å®ƒ')
        size_index = defect_info.get('size_index', 0)
        if 0 <= size_index < len(DefectConfig.SIZE_LIST):
            size_name = DefectConfig.SIZE_LIST[size_index]
            count[defect_class][size_name] += 1


def classification_worker(result_queue, classifier, count, batch_size=6):
    """
    åˆ†ç±»çº¿ç¨‹ï¼š
        - ä»é˜Ÿåˆ— result_queue å– (image_path, defects)
        - è¯»ç°åº¦å›¾ï¼ŒæŒ‰ batch åš classify_defects_batch
        - ç”¨ process_dataset æ›´æ–°ç»Ÿè®¡
    é˜Ÿåˆ—é‡Œæ”¶åˆ° None æ—¶é€€å‡ºã€‚
    """
    batch_images, batch_defects = [], []
    processed_count = 0
    cls_start = time.perf_counter()

    while True:
        item = result_queue.get()
        if item is None:
            break

        image_path, defects = item  # âœ… è½»é‡åŒ–ä¼ è¾“ï¼šä»…ä¼ è·¯å¾„ + defects
        image_np_gray = imread_unicode(image_path, cv2.IMREAD_GRAYSCALE)
        if image_np_gray is None:
            continue

        batch_images.append(image_np_gray)
        batch_defects.append(defects)

        if len(batch_images) >= batch_size:
            cls_batch_start = time.perf_counter()
            classify_results = classifier.classify_defects_batch(batch_images, batch_defects)
            cls_batch_end = time.perf_counter()
            batch_time = cls_batch_end - cls_batch_start
            processed_count += len(batch_images)
            avg_time = (cls_batch_end - cls_start) / processed_count
            speed = processed_count / (cls_batch_end - cls_start)

            print(
                f"[åˆ†ç±»çº¿ç¨‹] å·²åˆ†ç±» {processed_count} å¼  | "
                f"æœ¬æ‰¹è€—æ—¶ {batch_time:.3f}s | "
                f"å¹³å‡ {avg_time:.3f}s/å¼  | "
                f"é€Ÿåº¦ {speed:.2f} å¼ /ç§’ | "
                f"é˜Ÿåˆ—é•¿åº¦ {result_queue.qsize()}"
            )

            for result in classify_results:
                process_dataset(result, count)

            batch_images, batch_defects = [], []

    # å¤„ç†é˜Ÿåˆ—ç»“æŸåå‰©ä½™æœªæ»¡ batch çš„å†…å®¹
    if batch_images:
        classify_results = classifier.classify_defects_batch(batch_images, batch_defects)
        for result in classify_results:
            process_dataset(result, count)


# ------------------------
# 3. å•ä¸ªå­æ–‡ä»¶å¤¹å¤„ç†ï¼šå…‰ç…§æ£€æµ‹ + åˆ†å‰² + åˆ†ç±» + ç»Ÿè®¡
# ------------------------
def process_single_subfolder(subfolder_path, batch_size=6, queue_maxsize=200,
                             classifier=None, executor=None):
    """
    å¤„ç†å•ä¸ªå­æ–‡ä»¶å¤¹ï¼š
        1) ä»å­æ–‡ä»¶å¤¹è¯»å–æ‰€æœ‰å›¾åƒï¼ˆåªåˆ†å‰²+åˆ†ç±»ï¼Œä¸ä¿å­˜ï¼‰
        2) å¯¹é¦–å¼ å›¾åšå…‰ç…§æ£€æµ‹
        3) ç”¨è¿›ç¨‹æ± åšåˆ†å‰²ï¼›ç”¨åˆ†ç±»çº¿ç¨‹æ‰¹é‡åˆ†ç±»ï¼›æ›´æ–°å°ºå¯¸ç»Ÿè®¡
    è¿”å›ï¼š (å­æ–‡ä»¶å¤¹è·¯å¾„, å…‰ç…§æ£€æµ‹ç»“æœå­—ç¬¦ä¸², ç»Ÿè®¡å­—å…¸)
    """
    print(f"\nğŸ“‚ å¼€å§‹å¤„ç†å­æ–‡ä»¶å¤¹ï¼š{os.path.basename(subfolder_path)}")

    IMAGE_EXTS = (".jpg", ".jpeg", ".png", ".bmp", ".tiff")
    image_files = [
        os.path.join(subfolder_path, f)
        for f in sorted(os.listdir(subfolder_path))
        if f.lower().endswith(IMAGE_EXTS)
    ]
    if not image_files:
        print(f"[WARN] æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶ï¼š{os.path.basename(subfolder_path)}")
        return subfolder_path, "âš ï¸ æ— å›¾åƒ", {}

    # âœ… å…‰ç…§æ£€æµ‹ï¼ˆç”¨ä½ ç¤ºä¾‹é‡Œçš„å‚æ•°å½¢å¼ï¼Œä¼ è·¯å¾„ï¼‰
    first_img_path = image_files[0]
    print(f"\nğŸ“¸ å…‰ç…§æ£€æµ‹ï¼ˆæ ·æœ¬ï¼š{os.path.basename(first_img_path)}ï¼‰")
    light_result, light_pass = light_judge(
        input_image=first_img_path,
        background_range=(200, 225),
        num_slices=25,
        defect_gray_threshold=190,
        left=DefectConfig.LEFT_EDGE_X,
        right=DefectConfig.RIGHT_EDGE_X,
        too_dark=0.2,
        too_light=50,
        num_chunk=5,
    )
    print(f"ğŸ’¡ å…‰ç…§æ£€æµ‹ç»“æœï¼š{light_result}")
    if not light_pass:
        print(f"[WARN] å…‰ç…§æ£€æµ‹æœªé€šè¿‡ï¼Œä½†ç»§ç»­æ‰§è¡Œè¯¥æ–‡ä»¶å¤¹ç¼ºé™·æ£€æµ‹")

    # åˆå§‹åŒ–ç»Ÿè®¡ï¼šæ¯ä¸ªç±»åˆ« Ã— æ¯ä¸ªå°ºå¯¸æ®µ
    categories = ["é»‘ç‚¹", "æ™¶ç‚¹", "çº¤ç»´", "å…¶å®ƒ"]
    count = {cat: {size: 0 for size in DefectConfig.SIZE_LIST} for cat in categories}

    # å¯åŠ¨åˆ†ç±»çº¿ç¨‹ï¼ˆåªåšåˆ†ç±»+ç»Ÿè®¡ï¼Œä¸åšä»»ä½•ä¿å­˜/å‰ç«¯äº¤äº’ï¼‰
    manager = Manager()
    result_queue = manager.Queue(maxsize=queue_maxsize)
    cls_thread = threading.Thread(
        target=classification_worker,
        args=(result_queue, classifier, count, batch_size),
        daemon=True,
    )
    cls_thread.start()

    # ---------------- åˆ†å‰²éƒ¨åˆ† ----------------
    print(f"ğŸš€ å¯åŠ¨åˆ†å‰²ä»»åŠ¡ï¼Œå…± {len(image_files)} å¼ ")
    seg_start_all = time.perf_counter()
    completed = 0

    futures = [executor.submit(_segment_one_image, path) for path in image_files]
    for f in as_completed(futures):
        ok, image_path, defects = f.result()
        completed += 1
        elapsed = time.perf_counter() - seg_start_all
        avg_time = elapsed / completed
        if completed % 10 == 0 or completed == len(futures):
            print(f"[åˆ†å‰²è¿›åº¦] {completed}/{len(futures)} | {elapsed:.1f}s | {avg_time:.3f}s/å¼ ")
        if not ok:
            continue

        # é˜Ÿåˆ—æ»¡äº†å°±ç­‰ä¸€ä¸‹ï¼Œé˜²æ­¢ OOM
        while result_queue.full():
            print(f"âš ï¸ åˆ†ç±»é˜Ÿåˆ—å·²æ»¡ï¼Œç­‰å¾…æ¶ˆè´¹...")
            time.sleep(0.5)
        result_queue.put((image_path, defects))

    # é€šçŸ¥åˆ†ç±»çº¿ç¨‹ï¼šæ²¡æœ‰æ–°ä»»åŠ¡äº†
    result_queue.put(None)
    cls_thread.join()

    # âœ… å¼ºåˆ¶æ¸…ç†æ˜¾å­˜ä¸å†…å­˜
    torch.cuda.empty_cache()
    gc.collect()

    print(f"âœ… å­æ–‡ä»¶å¤¹å®Œæˆï¼š{os.path.basename(subfolder_path)}")
    return subfolder_path, light_result, count


# ------------------------
# 4. å¤šå­æ–‡ä»¶å¤¹æ‰¹é‡å¤„ç† + æ±‡æ€»æŠ¥å‘Š
# ------------------------
def process_multi_subfolders(root_input_folder, root_output_folder,
                             batch_size=6, max_workers=8, queue_maxsize=200,
                             report_name_level=1, custom_name=None):
    """
    å¤šæ–‡ä»¶å¤¹æ‰¹é‡æ£€æµ‹ï¼ˆä»…åˆ†å‰²+åˆ†ç±»+ç»Ÿè®¡ï¼‰ï¼š
        - root_input_folder ä¸‹æ¯ä¸ªå­ç›®å½•ä¸€ä¸ªâ€œæ‰¹æ¬¡â€
        - ä¸ä¿å­˜å›¾åƒï¼Œä¸ä¸å‰ç«¯äº¤äº’ï¼Œåªå†™ä¸€ä¸ªæ±‡æ€» txt æŠ¥å‘Š

    Args:
        root_input_folder: æ ¹è¾“å…¥ç›®å½•
        root_output_folder: æŠ¥å‘Šè¾“å‡ºç›®å½•
        batch_size: åˆ†ç±» batch å¤§å°
        max_workers: åˆ†å‰²è¿›ç¨‹æ•°
        queue_maxsize: åˆ†ç±»é˜Ÿåˆ—å®¹é‡
        report_name_level: æŠ¥å‘Šå‘½åç›®å½•å±‚çº§ï¼ˆ1=æœ€åä¸€å±‚, 2=å€’æ•°ç¬¬äºŒå±‚ï¼‰
        custom_name: è‡ªå®šä¹‰æŠ¥å‘Šåï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
    """
    print(f"ğŸ” å¯åŠ¨å¤šæ–‡ä»¶å¤¹æ‰¹é‡æ£€æµ‹: {root_input_folder}")
    if not os.path.exists(root_input_folder):
        print(f"[ERROR] è¾“å…¥è·¯å¾„ä¸å­˜åœ¨ï¼š{root_input_folder}")
        return

    os.makedirs(root_output_folder, exist_ok=True)

    # âœ… åŠ¨æ€æŠ¥å‘Šå‘½åé€»è¾‘
    path_parts = os.path.normpath(root_input_folder).split(os.sep)
    if custom_name:
        folder_name = custom_name
    elif len(path_parts) >= report_name_level:
        folder_name = path_parts[-report_name_level]
    else:
        folder_name = os.path.basename(os.path.normpath(root_input_folder))

    timestamp = time.strftime("%Y%m%d_%H%M%S")
    report_filename = f"{folder_name}_summary_{timestamp}.txt"
    report_path = os.path.join(root_output_folder, report_filename)
    print(f"ğŸ“„ æ±‡æ€»æŠ¥å‘Šå°†ä¿å­˜ä¸º: {report_filename}")

    subfolders = [
        os.path.join(root_input_folder, d)
        for d in os.listdir(root_input_folder)
        if os.path.isdir(os.path.join(root_input_folder, d))
    ]
    if not subfolders:
        print(f"[ERROR] æ²¡æœ‰å­æ–‡ä»¶å¤¹")
        return

    # âœ… å¤–å±‚åªåˆå§‹åŒ–ä¸€æ¬¡åˆ†ç±»å™¨å’Œè¿›ç¨‹æ± 
    defect_classifier = DefectClassifier()
    with ProcessPoolExecutor(max_workers=max_workers, initializer=_init_detector) as executor:
        results = []
        for subfolder in subfolders:
            res = process_single_subfolder(
                subfolder_path=subfolder,
                batch_size=batch_size,
                queue_maxsize=queue_maxsize,
                classifier=defect_classifier,
                executor=executor,
            )
            results.append(res)

    # âœ… å†™å‡ºæ±‡æ€»æŠ¥å‘Šï¼ˆçº¯æ–‡æœ¬ï¼Œä¸ä¿å­˜ä»»ä½•å›¾åƒï¼‰
    with open(report_path, "w", encoding="utf-8") as f:
        f.write("å¤šæ–‡ä»¶å¤¹ç¼ºé™·æ£€æµ‹æ±‡æ€»æŠ¥å‘Š\n")
        f.write(f"ç”Ÿæˆæ—¶é—´ï¼š{time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"è¾“å…¥æ ¹ç›®å½•ï¼š{root_input_folder}\n")
        f.write("=" * 80 + "\n\n")

        for subfolder_path, light_result, count in results:
            f.write(f"æ–‡ä»¶å¤¹: {os.path.basename(subfolder_path)}\n")
            f.write(f"å…‰ç…§æ£€æµ‹: {light_result}\n")
            f.write("class_name " + " ".join(DefectConfig.SIZE_LIST) + "\n")
            for cat in ["é»‘ç‚¹", "æ™¶ç‚¹", "çº¤ç»´", "å…¶å®ƒ"]:
                f.write(f"{cat} " + " ".join(str(count[cat][s]) for s in DefectConfig.SIZE_LIST) + "\n")
            f.write("-" * 80 + "\n\n")

    print(f"ğŸ‰ æ‰€æœ‰å­æ–‡ä»¶å¤¹å¤„ç†å®Œæˆï¼æŠ¥å‘Šä¿å­˜è‡³ {report_path}")


if __name__ == "__main__":
    # ğŸ‘‡ æŒ‰éœ€ä¿®æ”¹ä½ çš„è¾“å…¥/è¾“å‡ºè·¯å¾„
    ROOT_INPUT_FOLDER = r"G:\NEW\20250815\data2"
    ROOT_OUTPUT_FOLDER = "./output_summary_reports"

    process_multi_subfolders(
        root_input_folder=ROOT_INPUT_FOLDER,
        root_output_folder=ROOT_OUTPUT_FOLDER,
        batch_size=4,
        max_workers=8,
        queue_maxsize=512,
        report_name_level=2,       # âœ… ä½¿ç”¨å€’æ•°ç¬¬äºŒå±‚å‘½åï¼ˆä¾‹å¦‚ 20250815ï¼‰
        # custom_name="film_batchA" # âœ… æˆ–ä½¿ç”¨è‡ªå®šä¹‰åï¼ˆä¼˜å…ˆï¼‰
    )
