import os
import time
import gc

import cv2
import numpy as np
import torch

from detect_core.castfilm_detector import CastFilmDefectDetector
from detect_core.defect_classifier import DefectClassifier
from detect_core.defect_config import DefectConfig


def imread_unicode(path, flags=cv2.IMREAD_GRAYSCALE):
    """å®‰å…¨è¯»å–å›¾ç‰‡ï¼Œæ”¯æŒä¸­æ–‡è·¯å¾„"""
    try:
        with open(path, "rb") as f:
            file_bytes = np.frombuffer(f.read(), dtype=np.uint8)
            img = cv2.imdecode(file_bytes, flags)
            return img
    except Exception as e:
        print(f"âš ï¸ æ— æ³•è¯»å–æ–‡ä»¶: {os.path.basename(path)}, é”™è¯¯: {e}")
        return None


# ------------------------
# 1. ç»Ÿè®¡æ›´æ–°
# ------------------------
def process_dataset(classify_result, count):
    """
    ä»…æ›´æ–°ç»Ÿè®¡è®¡æ•°å™¨ï¼š
    å¯¹äºæ¯ä¸ªç¼ºé™·ï¼š
        - å– defect_classï¼ˆé»‘ç‚¹/æ™¶ç‚¹/çº¤ç»´/å…¶å®ƒï¼‰
        - å– size_index â†’ SIZE_LIST åç§°
        - åœ¨ count[defect_class][size_name] é‡Œ +1
    """
    cut_images = classify_result.get("cut_images", [])
    defect_infos = classify_result.get("defect_infos", [])
    for _, defect_info in zip(cut_images, defect_infos):
        defect_class = defect_info.get("defect_class", "å…¶å®ƒ")
        size_index = defect_info.get("size_index", 0)
        if 0 <= size_index < len(DefectConfig.SIZE_LIST):
            size_name = DefectConfig.SIZE_LIST[size_index]
            # å…œåº•ï¼šå¦‚æœåˆ†ç±»å™¨è¿”å›äº†æœªé¢„è®¾çš„ç±»åˆ«åï¼Œè‡ªåŠ¨å½’åˆ°â€œå…¶å®ƒâ€
            if defect_class not in count:
                defect_class = "å…¶å®ƒ"
            count[defect_class][size_name] += 1


# ------------------------
# 2. å•ä¸ªå­æ–‡ä»¶å¤¹å¤„ç†ï¼šåˆ†å‰² + åˆ†ç±» + ç»Ÿè®¡
#    ğŸ‘‰ å®Œå…¨å•çº¿ç¨‹é¡ºåºå¤„ç†
# ------------------------
def process_single_subfolder(
    subfolder_path,
    batch_size=6,
    queue_maxsize=200,
    classifier=None,
):
    """
    å¤„ç†å•ä¸ªå­æ–‡ä»¶å¤¹ï¼ˆå•çº¿ç¨‹ç‰ˆæœ¬ï¼‰ï¼š
        1) ä»å­æ–‡ä»¶å¤¹è¯»å–æ‰€æœ‰å›¾åƒ
        2) é¡ºåºå¤„ç†æ¯ä¸€å¼ ï¼šåˆ†å‰² -> åˆ†ç±» -> ç»Ÿè®¡
    è¿”å›ï¼š (å­æ–‡ä»¶å¤¹è·¯å¾„, ç»Ÿè®¡å­—å…¸)
    """
    print(f"\nğŸ“‚ å¼€å§‹å¤„ç†å­æ–‡ä»¶å¤¹ï¼š{os.path.basename(subfolder_path)}")

    IMAGE_EXTS = (".jpg", ".jpeg", ".png", ".bmp", ".tiff")
    image_files = [
        os.path.join(subfolder_path, f)
        for f in sorted(os.listdir(subfolder_path))
        if f.lower().endswith(IMAGE_EXTS)
    ]
    if not image_files:
        print(f"[WARN] æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶ï¼š{os.path.basename(subfolder_path)}")
        return subfolder_path, {}

    # åˆå§‹åŒ–ç»Ÿè®¡
    categories = ["é»‘ç‚¹", "æ™¶ç‚¹", "çº¤ç»´", "å…¶å®ƒ"]
    count = {cat: {size: 0 for size in DefectConfig.SIZE_LIST} for cat in categories}

    # âœ… åœ¨å½“å‰è¿›ç¨‹åˆå§‹åŒ–ä¸€æ¬¡æ£€æµ‹å™¨
    detector = CastFilmDefectDetector()

    # ---------------- é¡ºåºåˆ†å‰² + åˆ†ç±» ----------------
    print(f"ğŸš€ å¯åŠ¨åˆ†å‰²+åˆ†ç±»ä»»åŠ¡ï¼ˆå•çº¿ç¨‹ï¼‰ï¼Œå…± {len(image_files)} å¼ ")
    start_all = time.perf_counter()

    processed = 0
    for idx, image_path in enumerate(image_files, 1):
        img_gray = imread_unicode(image_path, cv2.IMREAD_GRAYSCALE)
        if img_gray is None:
            print(f"âš ï¸ æ— æ³•è¯»å–æ–‡ä»¶: {os.path.basename(image_path)}")
            continue

        try:
            # åˆ†å‰²
            seg_start = time.perf_counter()
            defects, left_edge_x, right_edge_x = detector.detect_defects_fast(img_gray)
            seg_time = time.perf_counter() - seg_start

            # ğŸ”¥ æ¯å¼ å›¾è¾“å‡ºç¼ºé™·æ•°é‡
            print(f"[ç¼ºé™·æ•°é‡] {os.path.basename(image_path)}: {len(defects)}")

            # åˆ†ç±»ï¼ˆä»ç„¶æŒ‰ 1 å¼ å›¾ä¸€é€ï¼›å¦‚æœä½ åç»­è¦æ”’ batchï¼Œå†æ”¹è¿™é‡Œï¼‰
            cls_start = time.perf_counter()
            classify_results = classifier.classify_defects_batch([img_gray], [defects])
            cls_time = time.perf_counter() - cls_start

            # ç»Ÿè®¡
            for result in classify_results:
                process_dataset(result, count)

            processed += 1
            elapsed = time.perf_counter() - start_all
            avg_time = elapsed / processed if processed > 0 else 0.0

            if idx % 10 == 0 or idx == len(image_files):
                print(
                    f"[è¿›åº¦] {idx}/{len(image_files)} | "
                    f"æ€»è€—æ—¶ {elapsed:.1f}s | å¹³å‡ {avg_time:.3f}s/å¼  | "
                    f"æœ€è¿‘ä¸€å¼ : åˆ†å‰² {seg_time:.3f}s + åˆ†ç±» {cls_time:.3f}s"
                )

        except Exception as e:
            print(f"âš ï¸ åˆ†å‰²/åˆ†ç±»é˜¶æ®µå‡ºé”™: {os.path.basename(image_path)}, é”™è¯¯: {e}")
            continue

        # å¯é€‰ï¼šé€‚å½“æ‰‹åŠ¨æ¸…ä¸€ä¸‹
        # del img_gray, defects, classify_results
        # gc.collect()

    # âœ… æ¸…ç†æ˜¾å­˜ä¸å†…å­˜
    torch.cuda.empty_cache()
    gc.collect()

    # ğŸ”¥ å­æ–‡ä»¶å¤¹ç¼ºé™·æ€»æ•°
    total_defects = sum(count[cat][size] for cat in count for size in count[cat])
    print(f"ğŸ“Š å­æ–‡ä»¶å¤¹ç¼ºé™·æ€»æ•°: {total_defects}")

    print(f"âœ… å­æ–‡ä»¶å¤¹å®Œæˆï¼š{os.path.basename(subfolder_path)}")
    return subfolder_path, count


# ------------------------
# 3. å¤šå­æ–‡ä»¶å¤¹æ‰¹é‡å¤„ç† + æ±‡æ€»æŠ¥å‘Š
#    ğŸ‘‰ å¤–å±‚é¡ºåºéå†å­æ–‡ä»¶å¤¹
# ------------------------
def process_multi_subfolders(
    root_input_folder,
    root_output_folder,
    batch_size=6,
    max_workers=8,
    queue_maxsize=200,
    report_name_level=1,
    custom_name=None,
):
    """
    å¤šæ–‡ä»¶å¤¹æ‰¹é‡æ£€æµ‹ï¼ˆå•çº¿ç¨‹ç‰ˆæœ¬ï¼‰ï¼š
        - root_input_folder ä¸‹æ¯ä¸ªå­ç›®å½•ä¾æ¬¡å¤„ç†
        - ä¸ä¿å­˜å›¾åƒï¼Œåªå†™ä¸€ä¸ªæ±‡æ€» txt æŠ¥å‘Š
    """
    print(f"ğŸ” å¯åŠ¨å¤šæ–‡ä»¶å¤¹æ‰¹é‡æ£€æµ‹: {root_input_folder}")
    if not os.path.exists(root_input_folder):
        print(f"[ERROR] è¾“å…¥è·¯å¾„ä¸å­˜åœ¨ï¼š{root_input_folder}")
        return

    os.makedirs(root_output_folder, exist_ok=True)

    # âœ… åŠ¨æ€æŠ¥å‘Šå‘½åé€»è¾‘
    path_parts = os.path.normpath(root_input_folder).split(os.sep)
    if custom_name:
        folder_name = custom_name
    elif len(path_parts) >= report_name_level:
        folder_name = path_parts[-report_name_level]
    else:
        folder_name = os.path.basename(os.path.normpath(root_input_folder))

    timestamp = time.strftime("%Y%m%d_%H%M%S")
    report_filename = f"{folder_name}_summary_{timestamp}.txt"
    report_path = os.path.join(root_output_folder, report_filename)
    print(f"ğŸ“„ æ±‡æ€»æŠ¥å‘Šå°†ä¿å­˜ä¸º: {report_filename}")

    subfolders = [
        os.path.join(root_input_folder, d)
        for d in os.listdir(root_input_folder)
        if os.path.isdir(os.path.join(root_input_folder, d))
    ]
    if not subfolders:
        print(f"[ERROR] æ²¡æœ‰å­æ–‡ä»¶å¤¹")
        return

    # âœ… å¤–å±‚åªåˆå§‹åŒ–ä¸€æ¬¡åˆ†ç±»å™¨
    defect_classifier = DefectClassifier()

    results = []
    for subfolder in subfolders:
        res = process_single_subfolder(
            subfolder_path=subfolder,
            batch_size=batch_size,
            queue_maxsize=queue_maxsize,
            classifier=defect_classifier,
        )
        results.append(res)

    # ğŸ”¥ è®¡ç®—æ‰€æœ‰å­æ–‡ä»¶å¤¹æ€»ç¼ºé™·æ•°é‡
    grand_total = 0
    for _, count in results:
        if not count:
            continue
        grand_total += sum(count[cat][size] for cat in count for size in count[cat])

    # âœ… å†™å‡ºæ±‡æ€»æŠ¥å‘Š
    with open(report_path, "w", encoding="utf-8") as f:
        f.write("å¤šæ–‡ä»¶å¤¹ç¼ºé™·æ£€æµ‹æ±‡æ€»æŠ¥å‘Šï¼ˆæ— å…‰ç…§æ£€æµ‹ï¼‰\n")
        f.write(f"ç”Ÿæˆæ—¶é—´ï¼š{time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"è¾“å…¥æ ¹ç›®å½•ï¼š{root_input_folder}\n")
        f.write("=" * 80 + "\n\n")

        for subfolder_path, count in results:
            f.write(f"æ–‡ä»¶å¤¹: {os.path.basename(subfolder_path)}\n")
            if count:
                subfolder_total = sum(
                    count[cat][size] for cat in count for size in count[cat]
                )
                f.write(f"ç¼ºé™·æ€»æ•°: {subfolder_total}\n")
                f.write("class_name " + " ".join(DefectConfig.SIZE_LIST) + "\n")
                for cat in ["é»‘ç‚¹", "æ™¶ç‚¹", "çº¤ç»´", "å…¶å®ƒ"]:
                    f.write(
                        f"{cat} "
                        + " ".join(str(count[cat][s]) for s in DefectConfig.SIZE_LIST)
                        + "\n"
                    )
            else:
                f.write("ç¼ºé™·ç»Ÿè®¡: æ— ï¼ˆè¯¥æ–‡ä»¶å¤¹æ— å›¾åƒæˆ–å¤„ç†å¤±è´¥ï¼‰\n")
            f.write("-" * 80 + "\n\n")

        f.write(f"æ‰€æœ‰å­æ–‡ä»¶å¤¹æ€»ç¼ºé™·æ•°é‡: {grand_total}\n")

    print(f"ğŸ¯ æ‰€æœ‰å­æ–‡ä»¶å¤¹æ€»ç¼ºé™·æ•°é‡ï¼š{grand_total}")
    print(f"ğŸ‰ æ‰€æœ‰å­æ–‡ä»¶å¤¹å¤„ç†å®Œæˆï¼æŠ¥å‘Šä¿å­˜è‡³ {report_path}")


if __name__ == "__main__":
    ROOT_INPUT_FOLDER = r"D:\castfilm-hc\data"
    ROOT_OUTPUT_FOLDER = r"./output_summary_reports"

    process_multi_subfolders(
        root_input_folder=ROOT_INPUT_FOLDER,
        root_output_folder=ROOT_OUTPUT_FOLDER,
        batch_size=4,          # ç›®å‰ä»æœªå®é™…ç”¨åˆ°ï¼ˆä½ åç»­è¦æ”’ batch å¯ç”¨ï¼‰
        max_workers=1,         # å•çº¿ç¨‹ç‰ˆæœ¬ï¼Œè¿™ä¸ªå‚æ•°æ— æ•ˆï¼Œä»…å ä½
        queue_maxsize=512,     # ç›®å‰æœªå®é™…ç”¨åˆ°ï¼ˆå ä½ï¼‰
        report_name_level=2,
        # custom_name="film_batchA"
    )
